{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a8481a-0493-40ec-a92b-9d26650dfc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Animal Detection by Wasim Sayyad ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d5bf429-9b9b-47ed-8775-b7f796b94c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from plyer import notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "978019c1-4347-4c0a-8465-98ff70eb0bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_SIZE = (150, 150)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 4\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "934d744e-3505-4707-acce-4698d20b6070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the paths\n",
    "train_dir = 'Animal_emotion_dataset/Master Folder/train'\n",
    "valid_dir = 'Animal_emotion_dataset/Master Folder/valid'\n",
    "test_dir = 'Animal_emotion_dataset/Master Folder/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5eae5d9-2d6c-4f50-b256-efdd5768d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation (training images)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e82b0f8a-820c-43e5-a021-ca0130908d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation\n",
    "valid_test_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46196830-d27d-4268-8fc2-0e5af798230c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1216 images belonging to 4 classes.\n",
      "Found 132 images belonging to 4 classes.\n",
      "Found 109 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Loading validation images\n",
    "valid_generator = valid_test_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Loading test images\n",
    "test_generator = valid_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7073002-d4c8-4970-84ad-cf7b6ea58e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main building of model, used max pooling and 2 layers for classification ~W\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a0d8d11-3e22-484e-9d5f-6bb7d0c22e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb898ac2-856b-4f94-a6a9-7650a6083b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have used a checkpoint to save the best model . \n",
    "checkpoint = ModelCheckpoint('animal_emotion_model.h5',\n",
    "                             monitor='val_accuracy',\n",
    "                             save_best_only=True,\n",
    "                             mode='max',\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "839cf310-7490-4b1f-9540-b8c65a0c91a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 1.3915 - accuracy: 0.2722\n",
      "Epoch 1: val_accuracy improved from -inf to 0.33594, saving model to animal_emotion_model.h5\n",
      "38/38 [==============================] - 42s 1s/step - loss: 1.3915 - accuracy: 0.2722 - val_loss: 1.3829 - val_accuracy: 0.3359\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 1.3856 - accuracy: 0.2697\n",
      "Epoch 2: val_accuracy did not improve from 0.33594\n",
      "38/38 [==============================] - 19s 510ms/step - loss: 1.3856 - accuracy: 0.2697 - val_loss: 1.3783 - val_accuracy: 0.3281\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 1.3845 - accuracy: 0.2747\n",
      "Epoch 3: val_accuracy did not improve from 0.33594\n",
      "38/38 [==============================] - 19s 509ms/step - loss: 1.3845 - accuracy: 0.2747 - val_loss: 1.3709 - val_accuracy: 0.3281\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 1.3821 - accuracy: 0.2763\n",
      "Epoch 4: val_accuracy did not improve from 0.33594\n",
      "38/38 [==============================] - 20s 518ms/step - loss: 1.3821 - accuracy: 0.2763 - val_loss: 1.3783 - val_accuracy: 0.3359\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 1.3812 - accuracy: 0.2788\n",
      "Epoch 5: val_accuracy did not improve from 0.33594\n",
      "38/38 [==============================] - 19s 493ms/step - loss: 1.3812 - accuracy: 0.2788 - val_loss: 1.3485 - val_accuracy: 0.3203\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 1.3751 - accuracy: 0.3109\n",
      "Epoch 6: val_accuracy did not improve from 0.33594\n",
      "38/38 [==============================] - 19s 504ms/step - loss: 1.3751 - accuracy: 0.3109 - val_loss: 1.3669 - val_accuracy: 0.3047\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 1.3777 - accuracy: 0.3035\n",
      "Epoch 7: val_accuracy improved from 0.33594 to 0.35156, saving model to animal_emotion_model.h5\n",
      "38/38 [==============================] - 20s 509ms/step - loss: 1.3777 - accuracy: 0.3035 - val_loss: 1.3527 - val_accuracy: 0.3516\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 1.3782 - accuracy: 0.2895\n",
      "Epoch 8: val_accuracy did not improve from 0.35156\n",
      "38/38 [==============================] - 19s 504ms/step - loss: 1.3782 - accuracy: 0.2895 - val_loss: 1.3719 - val_accuracy: 0.3438\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 1.3706 - accuracy: 0.3117\n",
      "Epoch 9: val_accuracy did not improve from 0.35156\n",
      "38/38 [==============================] - 20s 530ms/step - loss: 1.3706 - accuracy: 0.3117 - val_loss: 1.3703 - val_accuracy: 0.2656\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 1.3852 - accuracy: 0.2796\n",
      "Epoch 10: val_accuracy did not improve from 0.35156\n",
      "38/38 [==============================] - 20s 518ms/step - loss: 1.3852 - accuracy: 0.2796 - val_loss: 1.3854 - val_accuracy: 0.2969\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.samples // BATCH_SIZE,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a407ad-b09b-4fe3-a933-38d0964e9d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prediction\n",
    "model = load_model('animal_emotion_model.h5')\n",
    "\n",
    "predictions = model.predict(test_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "class_to_emotion = {0: 'Angry', 1: 'Sad', 2: 'Other', 3: 'Happy'}\n",
    "\n",
    "filenames = test_generator.filenames\n",
    "\n",
    "# this is for notifications\n",
    "for filename, predicted_class in zip(filenames, predicted_classes):\n",
    "    animal_name = filename.split('/')[0]\n",
    "    emotion = class_to_emotion[predicted_class]\n",
    "    # Shorten title and message\n",
    "    notification_title = f\"{animal_name[:15]} - {emotion[:15]} Emotion\"\n",
    "    notification_text = f\"{animal_name[:15]} is {emotion[:15]}!\"\n",
    "    notification.notify(title=notification_title, message=notification_text, app_icon=None, timeout=10)\n",
    "\n",
    "### evaluation (attempt - 4 )###3\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
